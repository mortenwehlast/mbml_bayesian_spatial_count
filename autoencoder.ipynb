{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "import torch.optim as optim\n",
    "\n",
    "from src.utils import load_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X-shape: (2095, 35), y-shape: (2095,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>youth_pop_5to18</th>\n",
       "      <th>commute_priv_vehicle</th>\n",
       "      <th>med_hhincome</th>\n",
       "      <th>avg_ann_daily_traffic</th>\n",
       "      <th>fragment_index</th>\n",
       "      <th>TotalPop</th>\n",
       "      <th>Men</th>\n",
       "      <th>Women</th>\n",
       "      <th>Hispanic</th>\n",
       "      <th>White</th>\n",
       "      <th>...</th>\n",
       "      <th>Transit</th>\n",
       "      <th>Walk</th>\n",
       "      <th>OtherTransp</th>\n",
       "      <th>WorkAtHome</th>\n",
       "      <th>Employed</th>\n",
       "      <th>PrivateWork</th>\n",
       "      <th>PublicWork</th>\n",
       "      <th>SelfEmployed</th>\n",
       "      <th>FamilyWork</th>\n",
       "      <th>Unemployment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>894</td>\n",
       "      <td>0.634634</td>\n",
       "      <td>74837</td>\n",
       "      <td>8682.0</td>\n",
       "      <td>-3.061385</td>\n",
       "      <td>5403</td>\n",
       "      <td>2659</td>\n",
       "      <td>2744</td>\n",
       "      <td>75.8</td>\n",
       "      <td>2.3</td>\n",
       "      <td>...</td>\n",
       "      <td>38.6</td>\n",
       "      <td>2.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2308</td>\n",
       "      <td>80.8</td>\n",
       "      <td>16.2</td>\n",
       "      <td>2.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1158</td>\n",
       "      <td>0.494977</td>\n",
       "      <td>77991</td>\n",
       "      <td>16917.0</td>\n",
       "      <td>-2.915361</td>\n",
       "      <td>5915</td>\n",
       "      <td>2896</td>\n",
       "      <td>3019</td>\n",
       "      <td>62.7</td>\n",
       "      <td>3.6</td>\n",
       "      <td>...</td>\n",
       "      <td>44.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2675</td>\n",
       "      <td>71.7</td>\n",
       "      <td>25.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>9.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1120</td>\n",
       "      <td>0.422405</td>\n",
       "      <td>32354</td>\n",
       "      <td>22712.0</td>\n",
       "      <td>-0.227456</td>\n",
       "      <td>5879</td>\n",
       "      <td>2558</td>\n",
       "      <td>3321</td>\n",
       "      <td>65.1</td>\n",
       "      <td>1.6</td>\n",
       "      <td>...</td>\n",
       "      <td>45.5</td>\n",
       "      <td>8.6</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.7</td>\n",
       "      <td>2120</td>\n",
       "      <td>75.0</td>\n",
       "      <td>21.3</td>\n",
       "      <td>3.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>281</td>\n",
       "      <td>0.199795</td>\n",
       "      <td>34635</td>\n",
       "      <td>124767.0</td>\n",
       "      <td>3.029461</td>\n",
       "      <td>2591</td>\n",
       "      <td>1206</td>\n",
       "      <td>1385</td>\n",
       "      <td>55.4</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>63.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>6.2</td>\n",
       "      <td>1083</td>\n",
       "      <td>76.8</td>\n",
       "      <td>15.5</td>\n",
       "      <td>7.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1998</td>\n",
       "      <td>0.286795</td>\n",
       "      <td>23423</td>\n",
       "      <td>10219.0</td>\n",
       "      <td>0.165237</td>\n",
       "      <td>8516</td>\n",
       "      <td>3301</td>\n",
       "      <td>5215</td>\n",
       "      <td>61.1</td>\n",
       "      <td>1.6</td>\n",
       "      <td>...</td>\n",
       "      <td>68.2</td>\n",
       "      <td>4.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2508</td>\n",
       "      <td>71.0</td>\n",
       "      <td>21.3</td>\n",
       "      <td>7.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   youth_pop_5to18  commute_priv_vehicle  med_hhincome  avg_ann_daily_traffic  \\\n",
       "0              894              0.634634         74837                 8682.0   \n",
       "1             1158              0.494977         77991                16917.0   \n",
       "2             1120              0.422405         32354                22712.0   \n",
       "3              281              0.199795         34635               124767.0   \n",
       "4             1998              0.286795         23423                10219.0   \n",
       "\n",
       "   fragment_index  TotalPop   Men  Women  Hispanic  White  ...  Transit  Walk  \\\n",
       "0       -3.061385      5403  2659   2744      75.8    2.3  ...     38.6   2.9   \n",
       "1       -2.915361      5915  2896   3019      62.7    3.6  ...     44.6   1.4   \n",
       "2       -0.227456      5879  2558   3321      65.1    1.6  ...     45.5   8.6   \n",
       "3        3.029461      2591  1206   1385      55.4    9.0  ...     63.9   3.0   \n",
       "4        0.165237      8516  3301   5215      61.1    1.6  ...     68.2   4.3   \n",
       "\n",
       "   OtherTransp  WorkAtHome  Employed  PrivateWork  PublicWork  SelfEmployed  \\\n",
       "0          0.0         0.0      2308         80.8        16.2           2.9   \n",
       "1          0.5         2.1      2675         71.7        25.3           2.5   \n",
       "2          1.6         1.7      2120         75.0        21.3           3.8   \n",
       "3          2.4         6.2      1083         76.8        15.5           7.7   \n",
       "4          1.0         0.0      2508         71.0        21.3           7.7   \n",
       "\n",
       "   FamilyWork  Unemployment  \n",
       "0         0.0           7.7  \n",
       "1         0.6           9.5  \n",
       "2         0.0           8.7  \n",
       "3         0.0          19.2  \n",
       "4         0.0          17.2  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y, k = load_data()\n",
    "print('X-shape: {}, y-shape: {}'.format(X.shape, y.shape)) \n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize input features.\n",
    "X_mean = X.mean(axis=0)\n",
    "X_std = X.std(axis=0)\n",
    "X = (X - X_mean) / X_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for model.\n",
    "X = torch.tensor(np.array(X)).float()\n",
    "y = torch.tensor(y).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    \n",
    "    \"\"\"An autoencoder\"\"\"\n",
    "    \n",
    "    \n",
    "    def __init__(self, input_shape, latent_features):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        \n",
    "        self.input_shape = input_shape\n",
    "        self.latent_features = latent_features\n",
    "        self.observation_features = np.prod(input_shape)\n",
    "\n",
    "        # Inference Network\n",
    "        # Encode the observation `x` into the parameters of the posterior distribution\n",
    "        # `q_\\phi(z|x) = N(z | \\mu(x), \\sigma(x)), \\mu(x),\\log\\sigma(x) = h_\\phi(x)`\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(in_features=self.observation_features, out_features=32),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(in_features=32, out_features=24),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(in_features=24, out_features=latent_features)\n",
    "        )\n",
    "        \n",
    "        # Generative Model\n",
    "        # Decode the latent sample `z` into the parameters of the observation model\n",
    "        # `p_\\theta(x | z) = \\prod_i B(x_i | g_\\theta(x))`\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(in_features=latent_features, out_features=24),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(in_features=24, out_features=32),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(in_features=32, out_features=self.observation_features)\n",
    "        )        \n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Run encoder and decoder, and output latent space together with reconstruction.\"\"\"\n",
    "        \n",
    "        # Latent space\n",
    "        h = self.encoder(x)\n",
    "\n",
    "        y = self.decoder(h)\n",
    "        \n",
    "        return h, y\n",
    "    \n",
    "    def encode(self, x):\n",
    "        \"\"\"Run encoder and decoder, and output latent space together with reconstruction.\"\"\"\n",
    "        \n",
    "        # Latent space\n",
    "        h = self.encoder(x)\n",
    "        \n",
    "        return h\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autoencoder(\n",
      "  (encoder): Sequential(\n",
      "    (0): Linear(in_features=35, out_features=32, bias=True)\n",
      "    (1): LeakyReLU(negative_slope=0.01)\n",
      "    (2): Linear(in_features=32, out_features=24, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=24, out_features=18, bias=True)\n",
      "  )\n",
      "  (decoder): Sequential(\n",
      "    (0): Linear(in_features=18, out_features=24, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=24, out_features=32, bias=True)\n",
      "    (3): LeakyReLU(negative_slope=0.01)\n",
      "    (4): Linear(in_features=32, out_features=35, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "latent_features = 18\n",
    "ae = Autoencoder(X.shape[1], latent_features)\n",
    "print(ae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device cuda\n"
     ]
    }
   ],
   "source": [
    "# Load model.\n",
    "device = torch.device('cpu' if not torch.cuda.is_available() else 'cuda')\n",
    "ae.to(device)\n",
    "print(\"Running on device\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create data loader for batch handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "X_train = X[:1800]\n",
    "X_test = X[1800:]\n",
    "\n",
    "# Output currently not used.\n",
    "y_train = y[:1800]\n",
    "y_test = y[1800:]\n",
    "\n",
    "data_train = TensorDataset(X_train, y_train)\n",
    "\n",
    "batch_size = 64\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    data_train, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch : 169/200, train_loss = 0.3145, test_loss = 0.4239:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 169/200 [05:24<01:03,  2.03s/it]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Train model.\n",
    "epochs = 200\n",
    "eval_every = 1\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(ae.parameters(), lr=0.0001)\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "t = tqdm(range(epochs))\n",
    "for epoch in t:\n",
    "\n",
    "    # Training.\n",
    "    ae.train()    \n",
    "\n",
    "    for x, _ in train_loader:\n",
    "\n",
    "        x = x.to(device)\n",
    "        \n",
    "        h, x_recon = ae(x)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # compute training reconstruction loss\n",
    "        loss = criterion(x_recon, x)\n",
    "        \n",
    "        # compute accumulated gradients\n",
    "        loss.backward()\n",
    "        \n",
    "        # perform parameter update based on current gradients\n",
    "        optimizer.step()\n",
    "        \n",
    "    ae.eval()\n",
    "    if epoch % eval_every == 0:\n",
    "        # Train evaluation.\n",
    "        x = X_train.to(device)\n",
    "        h, x_recon = ae(x)\n",
    "        # compute training reconstruction loss\n",
    "        train_loss = criterion(x_recon, x).item()\n",
    "        \n",
    "        x = X_test.to(device)\n",
    "        h, x_recon = ae(x)\n",
    "        # compute test reconstruction loss\n",
    "        test_loss = criterion(x_recon, x).item()\n",
    "        \n",
    "        train_losses.append(train_loss)\n",
    "        test_losses.append(test_loss)\n",
    "    \n",
    "    # display the epoch training loss\n",
    "    t.set_description(\"epoch : {}/{}, train_loss = {:.4f}, test_loss = {:.4f}\".format(epoch + 1, epochs, train_loss, test_loss))\n",
    "    t.refresh() # to show immediately the update\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(train_losses, label='Train loss')\n",
    "plt.plot(test_losses, label='Test loss')\n",
    "plt.legend()\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('MSE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot example of reconstruction of the 35 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.show()\n",
    "plt.plot(X[0], label='Orig')\n",
    "plt.plot(ae(X[0].to(device))[1].detach().cpu().numpy(), label='Recon')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
